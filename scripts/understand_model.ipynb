{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from prismatic.models import get_llm_backbone_and_tokenizer, get_vision_backbone_and_transform, get_vlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">04/13 [10:16:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; Loading pretrained weights from Hugging Face hub                     <a href=\"file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_builder.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_builder.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_builder.py#186\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">186</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"font-weight: bold\">(</span>timm/vit_large_patch14_reg4_dinov2.lvd142m<span style=\"font-weight: bold\">)</span>                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m04/13 [10:16:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> Loading pretrained weights from Hugging Face hub                     \u001b]8;id=318321;file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_builder.py\u001b\\\u001b[2m_builder.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=809947;file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_builder.py#186\u001b\\\u001b[2m186\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[1m(\u001b[0mtimm/vit_large_patch14_reg4_dinov2.lvd142m\u001b[1m)\u001b[0m                              \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">04/13 [10:16:52] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt;  Safe alternative available for <span style=\"color: #008000; text-decoration-color: #008000\">'pytorch_model.bin'</span> <span style=\"font-weight: bold\">(</span>as                  <a href=\"file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_hub.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_hub.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_hub.py#180\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'model.safetensors'</span><span style=\"font-weight: bold\">)</span>. Loading weights using safetensors.                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m04/13 [10:16:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >>  Safe alternative available for \u001b[32m'pytorch_model.bin'\u001b[0m \u001b[1m(\u001b[0mas                  \u001b]8;id=431095;file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_hub.py\u001b\\\u001b[2m_hub.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=647772;file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_hub.py#180\u001b\\\u001b[2m180\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[32m'model.safetensors'\u001b[0m\u001b[1m)\u001b[0m. Loading weights using safetensors.                      \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; Resized position embedding: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span><span style=\"font-weight: bold\">)</span> to <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span><span style=\"font-weight: bold\">)</span>.                    <a href=\"file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/layers/pos_embed.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pos_embed.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/layers/pos_embed.py#55\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> Resized position embedding: \u001b[1m(\u001b[0m\u001b[1;36m37\u001b[0m, \u001b[1;36m37\u001b[0m\u001b[1m)\u001b[0m to \u001b[1m(\u001b[0m\u001b[1;36m27\u001b[0m, \u001b[1;36m27\u001b[0m\u001b[1m)\u001b[0m.                    \u001b]8;id=284552;file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/layers/pos_embed.py\u001b\\\u001b[2mpos_embed.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=467854;file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/layers/pos_embed.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">04/13 [10:17:00] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt; Loading pretrained weights from Hugging Face hub                     <a href=\"file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_builder.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_builder.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_builder.py#186\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">186</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"font-weight: bold\">((</span><span style=\"color: #008000; text-decoration-color: #008000\">'timm/ViT-SO400M-14-SigLIP-384'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'open_clip_pytorch_model.bin'</span><span style=\"font-weight: bold\">))</span>        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m04/13 [10:17:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >> Loading pretrained weights from Hugging Face hub                     \u001b]8;id=374566;file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_builder.py\u001b\\\u001b[2m_builder.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=430082;file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_builder.py#186\u001b\\\u001b[2m186\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'timm/ViT-SO400M-14-SigLIP-384'\u001b[0m, \u001b[32m'open_clip_pytorch_model.bin'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt;  Safe alternative available for <span style=\"color: #008000; text-decoration-color: #008000\">'open_clip_pytorch_model.bin'</span> <span style=\"font-weight: bold\">(</span>as        <a href=\"file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_hub.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_hub.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_hub.py#180\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'open_clip_model.safetensors'</span><span style=\"font-weight: bold\">)</span>. Loading weights using safetensors.            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >>  Safe alternative available for \u001b[32m'open_clip_pytorch_model.bin'\u001b[0m \u001b[1m(\u001b[0mas        \u001b]8;id=288606;file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_hub.py\u001b\\\u001b[2m_hub.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=49785;file:///home/localstorage/miniconda3/envs/prismatic/lib/python3.10/site-packages/timm/models/_hub.py#180\u001b\\\u001b[2m180\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         \u001b[32m'open_clip_model.safetensors'\u001b[0m\u001b[1m)\u001b[0m. Loading weights using safetensors.            \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vision_backbone, image_transform = get_vision_backbone_and_transform(\n",
    "        \"dinosiglip-vit-so-384px\", image_resize_strategy=\"resize-naive\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">04/13 [10:17:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt;     |=&gt; Loading <span style=\"font-weight: bold\">phi2</span> LLM from <span style=\"text-decoration: underline\">`microsoft/phi-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold; text-decoration: underline\">2</span><span style=\"text-decoration: underline\">`</span>                      <a href=\"file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/backbones/llm/base_llm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_llm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/backbones/llm/base_llm.py#118\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m04/13 [10:17:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >>     |=> Loading \u001b[1mphi2\u001b[0m LLM from \u001b[4m`microsoft/phi-\u001b[0m\u001b[1;4;36m2\u001b[0m\u001b[4m`\u001b[0m                      \u001b]8;id=503762;file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/backbones/llm/base_llm.py\u001b\\\u001b[2mbase_llm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=980734;file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/backbones/llm/base_llm.py#118\u001b\\\u001b[2m118\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">04/13 [10:17:26] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt;     |=&gt; Loading <span style=\"font-weight: bold\">phi2</span> <span style=\"font-weight: bold\">(</span>Fast<span style=\"font-weight: bold\">)</span> Tokenizer via the AutoTokenizer API      <a href=\"file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/backbones/llm/base_llm.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">base_llm.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/backbones/llm/base_llm.py#163\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m04/13 [10:17:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >>     |=> Loading \u001b[1mphi2\u001b[0m \u001b[1m(\u001b[0mFast\u001b[1m)\u001b[0m Tokenizer via the AutoTokenizer API      \u001b]8;id=268065;file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/backbones/llm/base_llm.py\u001b\\\u001b[2mbase_llm.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=824709;file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/backbones/llm/base_llm.py#163\u001b\\\u001b[2m163\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_backbone, tokenizer = get_llm_backbone_and_tokenizer(\n",
    "        \"phi2_base\", llm_max_length=2048\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi2LLMBackbone(\n",
      "  (llm): PeftModelForCausalLM(\n",
      "    (base_model): LoraModel(\n",
      "      (model): PhiForCausalLM(\n",
      "        (model): PhiModel(\n",
      "          (embed_tokens): Embedding(50295, 2560)\n",
      "          (embed_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (layers): ModuleList(\n",
      "            (0-31): 32 x PhiDecoderLayer(\n",
      "              (self_attn): PhiAttention(\n",
      "                (q_proj): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.05, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (k_proj): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "                (v_proj): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.05, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=2560, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=2560, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
      "                (rotary_emb): PhiRotaryEmbedding()\n",
      "              )\n",
      "              (mlp): PhiMLP(\n",
      "                (activation_fn): NewGELUActivation()\n",
      "                (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "                (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "              )\n",
      "              (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (lm_head): Linear(in_features=2560, out_features=50295, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vlm = get_vlm(\n",
    "    model_id = \"dino-siglip-phi2\",\n",
    "    arch_specifier = \"gelu-mlp\",\n",
    "    vision_backbone = vision_backbone,\n",
    "    llm_backbone = llm_backbone,\n",
    ")\n",
    "print(vlm.llm_backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">04/13 [10:17:48] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt;     |=&gt; <span style=\"font-weight: bold\">[</span>Frozen<span style=\"font-weight: bold\">]</span>    ðŸ¥¶ =&gt;&gt; Vision Backbone                          <a href=\"file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">prismatic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py#170\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span>         `dinosiglip-vit-so-384px`                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m04/13 [10:17:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >>     |=> \u001b[1m[\u001b[0mFrozen\u001b[1m]\u001b[0m    ðŸ¥¶ =>> Vision Backbone                          \u001b]8;id=264245;file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py\u001b\\\u001b[2mprismatic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=899004;file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py#170\u001b\\\u001b[2m170\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                 \u001b[0m         `dinosiglip-vit-so-384px`                                                \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt;     |=&gt; <span style=\"font-weight: bold\">[</span>TRAINABLE<span style=\"font-weight: bold\">]</span> ðŸ”¥ =&gt;&gt; LLM Backbone `phi2_base`                 <a href=\"file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">prismatic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py#171\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">171</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >>     |=> \u001b[1m[\u001b[0mTRAINABLE\u001b[1m]\u001b[0m ðŸ”¥ =>> LLM Backbone `phi2_base`                 \u001b]8;id=15582;file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py\u001b\\\u001b[2mprismatic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=120664;file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py#171\u001b\\\u001b[2m171\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> | &gt;&gt;     |=&gt; <span style=\"font-weight: bold\">[</span>TRAINABLE<span style=\"font-weight: bold\">]</span> ðŸ”¥ =&gt;&gt; Projector `gelu-mlp`                     <a href=\"file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">prismatic.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py#172\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m | >>     |=> \u001b[1m[\u001b[0mTRAINABLE\u001b[1m]\u001b[0m ðŸ”¥ =>> Projector `gelu-mlp`                     \u001b]8;id=193329;file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py\u001b\\\u001b[2mprismatic.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=19894;file:///home/DSO_SSD/Nithish/LVLMs/prismatic-vlms/prismatic/models/vlms/prismatic.py#172\u001b\\\u001b[2m172\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params =  3521740983\n",
      "Trainable params =  14750720\n"
     ]
    }
   ],
   "source": [
    "vlm.freeze_backbones(stage=\"finetune\")\n",
    "\n",
    "print(\"Total params = \",sum(p.numel() for p in vlm.parameters()))\n",
    "print(\"Trainable params = \",sum(p.numel() for p in vlm.parameters() if p.requires_grad))\n",
    "\n",
    "#       original\n",
    "# Total params =  3,519,119,543\n",
    "# Trainable params =  3,519,119,543\n",
    "\n",
    "#       align\n",
    "# Total params =  3,519,119,543\n",
    "# Trainable params =  12,129,280\n",
    "\n",
    "# \"finetune\" without LoRA ; commented the line # self.llm_backbone.requires_grad_(True) in prismatic.py\n",
    "# Total params =  3519119543\n",
    "# Trainable params =  2787178615\n",
    "\n",
    "# \"finetune\" with LoRA ; commented the line # self.llm_backbone.requires_grad_(True) in prismatic.py\n",
    "# Total params =  3521740983\n",
    "# Trainable params =  14750720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi2 <|endoftext|> <|endoftext|>  0\n"
     ]
    }
   ],
   "source": [
    "prompter = vlm.get_prompt_builder()\n",
    "prompter = PurePromptBuilder(model_family=\"phi2\")\n",
    "print(prompter.model_family, prompter.bos, prompter.eos, prompter.prompt, prompter.turn_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " In: How many apples are in this picture?\n",
      "Out:  1\n",
      "\n",
      " In: How many apples are in this picture?\n",
      "Out: There are 10 apples.<|endoftext|> 2\n",
      "\n",
      " In: How many apples are in this picture?\n",
      "Out: There are 10 apples.<|endoftext|>In: How many oranges are in this picture?\n",
      "Out:  3\n",
      "\n",
      " In: How many apples are in this picture?\n",
      "Out: There are 10 apples.<|endoftext|>In: How many oranges are in this picture?\n",
      "Out:  <|endoftext|> 4\n"
     ]
    }
   ],
   "source": [
    "prompter.add_turn(\n",
    "    role = \"human\",\n",
    "    message = \"<image> How many apples are in this picture?\"\n",
    ")\n",
    "print(\"\\n\",prompter.prompt, prompter.turn_count)\n",
    "\n",
    "prompter.add_turn(\n",
    "    role = \"gpt\",\n",
    "    message = \"There are 10 apples.\"\n",
    ")\n",
    "print(\"\\n\",prompter.prompt, prompter.turn_count)\n",
    "\n",
    "prompter.add_turn(\n",
    "    role = \"human\",\n",
    "    message = \"<image> How many oranges are in this picture?\"\n",
    ")\n",
    "print(\"\\n\",prompter.prompt, prompter.turn_count)\n",
    "\n",
    "prompter.add_turn(\n",
    "    role = \"gpt\",\n",
    "    message = \"There are no oranges in this picture.\"\n",
    ")\n",
    "print(\"\\n\",prompter.prompt, prompter.turn_count)\n",
    "\n",
    "# PurePromptBuilder doesnot include system prompt yet!\n",
    "# <|endoftext|> appearing in chat history ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prismatic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
